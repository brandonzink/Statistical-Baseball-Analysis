{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289 entries, 0 to 288\n",
      "Data columns (total 14 columns):\n",
      "G                289 non-null int64\n",
      "HR               289 non-null int64\n",
      "RBI              289 non-null int64\n",
      "BB_percentage    289 non-null float64\n",
      "K_percentage     289 non-null float64\n",
      "ISO              289 non-null float64\n",
      "BABIP            289 non-null float64\n",
      "AVG              289 non-null float64\n",
      "OBP              289 non-null float64\n",
      "SLG              289 non-null float64\n",
      "wOBA             289 non-null float64\n",
      "wRC_plus         289 non-null int64\n",
      "BsR              289 non-null float64\n",
      "WAR              289 non-null float64\n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 31.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>BB_percentage</th>\n",
       "      <th>K_percentage</th>\n",
       "      <th>ISO</th>\n",
       "      <th>BABIP</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>wOBA</th>\n",
       "      <th>wRC_plus</th>\n",
       "      <th>BsR</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>589</td>\n",
       "      <td>139</td>\n",
       "      <td>373</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.417</td>\n",
       "      <td>171</td>\n",
       "      <td>23.1</td>\n",
       "      <td>32.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>140</td>\n",
       "      <td>398</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.386</td>\n",
       "      <td>147</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>626</td>\n",
       "      <td>70</td>\n",
       "      <td>302</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.376</td>\n",
       "      <td>143</td>\n",
       "      <td>5.3</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581</td>\n",
       "      <td>112</td>\n",
       "      <td>394</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.400</td>\n",
       "      <td>148</td>\n",
       "      <td>15.2</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>457</td>\n",
       "      <td>94</td>\n",
       "      <td>274</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.389</td>\n",
       "      <td>143</td>\n",
       "      <td>19.2</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     G   HR  RBI  BB_percentage  K_percentage    ISO  BABIP    AVG    OBP  \\\n",
       "0  589  139  373          0.150         0.221  0.278  0.348  0.301  0.413   \n",
       "1  584  140  398          0.128         0.189  0.254  0.296  0.277  0.375   \n",
       "2  626   70  302          0.067         0.099  0.162  0.351  0.334  0.384   \n",
       "3  581  112  394          0.152         0.219  0.236  0.363  0.304  0.413   \n",
       "4  457   94  274          0.123         0.239  0.240  0.346  0.288  0.388   \n",
       "\n",
       "     SLG   wOBA  wRC_plus   BsR   WAR  \n",
       "0  0.579  0.417       171  23.1  32.9  \n",
       "1  0.531  0.386       147   5.1  28.0  \n",
       "2  0.496  0.376       143   5.3  23.9  \n",
       "3  0.540  0.400       148  15.2  21.7  \n",
       "4  0.527  0.389       143  19.2  21.6  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the .csv stored in a folder in the library, I got it off of Fangraphs\n",
    "dfStats = pd.read_csv(\"Data/OffensiveStats2014-2017.csv\")\n",
    "\n",
    "#This drops the columns I don't need for the regression, with axis=1 (columns, not rows)\n",
    "dfStats = dfStats.drop('Name', 1)\n",
    "dfStats = dfStats.drop('Team', 1)\n",
    "dfStats = dfStats.drop('SB', 1)\n",
    "dfStats = dfStats.drop('Off', 1)\n",
    "dfStats = dfStats.drop('Def', 1)\n",
    "dfStats = dfStats.drop('playerid', 1)\n",
    "dfStats = dfStats.drop('R', 1)\n",
    "dfStats = dfStats.drop('PA', 1)\n",
    "\n",
    "#This cleans the data. In BB% and K%, there was a % and a space, which screws up turning it into a numeric value.\n",
    "#I first replace the % and space with nothing to get rid of it (first four lines), then I use pandas \"to_numeric\" to\n",
    "#change the value into a float, then I divide by 100 to get to decimal percent (0.15 instead of 15%)\n",
    "dfStats['BB%'] = dfStats['BB%'].str.replace('%', '')\n",
    "dfStats['K%'] = dfStats['K%'].str.replace('%', '')\n",
    "dfStats['BB%'] = dfStats['BB%'].str.replace(' ', '')\n",
    "dfStats['K%'] = dfStats['K%'].str.replace(' ', '')\n",
    "dfStats[['BB%','K%']] = dfStats[['BB%','K%']].apply(pd.to_numeric, errors='ignore')\n",
    "dfStats['BB%'] = dfStats['BB%']/100\n",
    "dfStats['K%'] = dfStats['K%']/100\n",
    "\n",
    "#This renames some columns becuase the % or + symbol screws up the regression\n",
    "dfStats = dfStats.rename(columns={'K%':'K_percentage'})\n",
    "dfStats = dfStats.rename(columns={'BB%':'BB_percentage'})\n",
    "dfStats = dfStats.rename(columns={'wRC+':'wRC_plus'})\n",
    "\n",
    "#This gives the name, length and type of every column\n",
    "dfStats.info()\n",
    "#This prints out the first five rows, just to double check things\n",
    "dfStats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have the data in the form that we want it. All of the values are in a numeric form (either int or float), and we've dropped the columns that don't help us. We won't change this dataframe anymore, if we want to drop columns later on, we'll create a new dataframe without the columns we want to get rid of (I don't know if we will want to do this yet), so that this will always remain the \"base\" dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "WAR = \\frac{Batting Runs + Base Running Runs +Fielding Runs + Positional Adjustment + League Adjustment +Replacement Runs}{Runs Per Win}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the calculation for WAR by FanGraphs, which is nice becuase it doesn't use any of the raw stats (PA, HR, R, RBI, BB%, K%, and the such. I'm sure it uses these in some of the calculations, but it makes it so that they are not apparent for the linear regression. So let's run it with this entire dataframe and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So this is  a function I wrote for class that chooses the first \"maxk\" options that have the greatest impact on the\n",
    "#linear regression. It's very complicated to explain exactly how it works, but it runs certain stats for each column, sorts\n",
    "#the columns by impact, and then chooses the first maxk ones and uses statsmodels.formula.api library to make a model\n",
    "def forward_select(df, resp_str , maxk):\n",
    "    remaining = set(df.columns)\n",
    "    remaining.remove(resp_str)\n",
    "    selected = []\n",
    "    numselected = 1\n",
    "    score_crnt, score_new = 0.0, 0.0\n",
    "    while remaining and score_crnt == score_new:\n",
    "        score_array = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(resp_str,' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, df).fit().rsquared_adj\n",
    "            score_array.append((score, candidate))\n",
    "        score_array.sort()\n",
    "        score_new, best_option = score_array.pop()\n",
    "        if score_crnt < score_new and numselected <= maxk:\n",
    "            remaining.remove(best_option)\n",
    "            selected.append(best_option)\n",
    "            score_crnt = score_new\n",
    "            numselected += 1\n",
    "    formula = \"{} ~ {} + 1\".format(resp_str,' + '.join(selected))\n",
    "    model = smf.ols(formula, df).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>WAR</td>       <th>  R-squared:         </th> <td>   0.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   166.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Dec 2017</td> <th>  Prob (F-statistic):</th> <td>5.04e-82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:48:59</td>     <th>  Log-Likelihood:    </th> <td> -714.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   289</td>      <th>  AIC:               </th> <td>   1441.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   283</td>      <th>  BIC:               </th> <td>   1463.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>  -15.8289</td> <td>    1.808</td> <td>   -8.755</td> <td> 0.000</td> <td>  -19.388   -12.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wRC_plus</th>     <td>    0.1821</td> <td>    0.014</td> <td>   13.243</td> <td> 0.000</td> <td>    0.155     0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BsR</th>          <td>    0.1964</td> <td>    0.018</td> <td>   11.010</td> <td> 0.000</td> <td>    0.161     0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>G</th>            <td>    0.0100</td> <td>    0.003</td> <td>    3.161</td> <td> 0.002</td> <td>    0.004     0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>K_percentage</th> <td>  -12.6889</td> <td>    3.342</td> <td>   -3.797</td> <td> 0.000</td> <td>  -19.268    -6.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RBI</th>          <td>    0.0103</td> <td>    0.005</td> <td>    2.201</td> <td> 0.029</td> <td>    0.001     0.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.375</td> <th>  Durbin-Watson:     </th> <td>   1.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.041</td> <th>  Jarque-Bera (JB):  </th> <td>   5.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.247</td> <th>  Prob(JB):          </th> <td>  0.0691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.553</td> <th>  Cond. No.          </th> <td>1.09e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    WAR   R-squared:                       0.746\n",
       "Model:                            OLS   Adj. R-squared:                  0.742\n",
       "Method:                 Least Squares   F-statistic:                     166.2\n",
       "Date:                Sun, 24 Dec 2017   Prob (F-statistic):           5.04e-82\n",
       "Time:                        17:48:59   Log-Likelihood:                -714.64\n",
       "No. Observations:                 289   AIC:                             1441.\n",
       "Df Residuals:                     283   BIC:                             1463.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept      -15.8289      1.808     -8.755      0.000       -19.388   -12.270\n",
       "wRC_plus         0.1821      0.014     13.243      0.000         0.155     0.209\n",
       "BsR              0.1964      0.018     11.010      0.000         0.161     0.232\n",
       "G                0.0100      0.003      3.161      0.002         0.004     0.016\n",
       "K_percentage   -12.6889      3.342     -3.797      0.000       -19.268    -6.110\n",
       "RBI              0.0103      0.005      2.201      0.029         0.001     0.019\n",
       "==============================================================================\n",
       "Omnibus:                        6.375   Durbin-Watson:                   1.401\n",
       "Prob(Omnibus):                  0.041   Jarque-Bera (JB):                5.344\n",
       "Skew:                           0.247   Prob(JB):                       0.0691\n",
       "Kurtosis:                       2.553   Cond. No.                     1.09e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.09e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = forward_select(dfStats, \"WAR\", 5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a complicated model to interpret, but you don't need all the info. R-squared and Adj. R-Squared model what percentage of the response variable variation that is explained by a linear model, and Adj. R-squared takes into account the number of variables in the regression and recalculates the percentage.  \n",
    "  \n",
    "The F-statistic is the same as a T-statistic, but with a linear regression, and what is more helpful is the Prob (F-statistic), which is the p-value. This has a p-value of $5.04*10^{-82}$. We're going to assume an alpha level of 0.05 (reject versus fail to reject the null-hypothesis), so this means this linear regression is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we interpet. The way to intepret the bottom part, which gives us the model, is the column head on the left, multiplied by the coef (coefficent), all added together. The P>|t| is the p-value for each individial statistic, so we want it to be lwoer than 0.05 as well. So our regression model is:  \n",
    "$$  \n",
    "WAR=-15.82+([wRC+]*0.182)+(BsR*0.196)+(G*0.01)+(Kpercentage*-12.69)+(RBI*0.01)  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell from this that there is a positive correaltion between WAR and wRC+, BsR, G, and RBI, and a negative correlation between K% and WAR (suprise), and they all have extremely strong correlations but for RBI, which is weaker but significant. This doesn't tell us a ton, so maybe we'll drop a few of these varaibles and try again when I get more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
